{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some utility functions\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_daily = pd.read_csv('./time_series_data/btc_daily_all.csv')\n",
    "btc_daily = clean_data(btc_daily,'btc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_daily = pd.read_csv('./time_series_data/eth_daily_all.csv')\n",
    "eth_daily = clean_data(eth_daily,'eth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrp_daily = pd.read_csv('./time_series_data/xrp_daily_all.csv')\n",
    "xrp_daily = clean_data(xrp_daily,'xrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc_daily = pd.read_csv('./time_series_data/ltc_daily_all.csv')\n",
    "ltc_daily = clean_data(ltc_daily,'ltc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmr_daily = pd.read_csv('./time_series_data/xmr_daily_all.csv')\n",
    "xmr_daily = clean_data(xmr_daily,'xmr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_daily = pd.read_csv('./time_series_data/dash_daily_all.csv')\n",
    "dash_daily = clean_data(dash_daily,'dash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xem_daily = pd.read_csv('./time_series_data/xem_daily_all.csv')\n",
    "xem_daily = clean_data(xem_daily,'xem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_daily = pd.read_csv('./time_series_data/bcn_daily_all.csv')\n",
    "bcn_daily = clean_data(bcn_daily,'bcn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all cryptocurrencies data together\n",
    "# using left join to make sure all bitcoin data are included\n",
    "coin_total = btc_daily.join([eth_daily,xrp_daily,ltc_daily,xmr_daily,dash_daily,xem_daily,bcn_daily],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_complete = coin_total.dropna(axis=0)       # complete daily prices and volumes for 8 cryptocurrencies\n",
    "                                                # could do some time series analysis on this part\n",
    "                                                # add other indices later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_daily = pd.read_csv('./time_series_data/^GSPC.csv')\n",
    "sp500_daily = clean_data(sp500_daily,'sp500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n225_daily = pd.read_csv('./time_series_data/^N225.csv')\n",
    "n225_daily = clean_data(n225_daily,'n225')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sxxp_daily = pd.read_csv('./time_series_data/^SXXP.csv')\n",
    "sxxp_daily = clean_data(sxxp_daily,'sxxp',True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_daily = pd.read_csv('./time_series_data/^VIX.csv')\n",
    "vix_daily = clean_data(vix_daily,'vix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxsq_daily = pd.read_csv('./time_series_data/DXSQ.F.csv')\n",
    "dxsq_daily = clean_data(dxsq_daily,'dxsq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_daily = pd.read_csv('./time_series_data/metal.csv')\n",
    "metal_daily = metal_daily.iloc[:,[0,1,3]]\n",
    "metal_daily['Date'] = pd.to_datetime(metal_daily['Date'],format=\"%Y-%m-%d\")\n",
    "metal_daily = metal_daily.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "int1mo_daily = pd.read_csv('./time_series_data/ustreasuryrates_1mo.csv')\n",
    "int1mo_daily = clean_data(int1mo_daily,'',False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "int10y_daily = pd.read_csv('./time_series_data/ustreasuryrates_10y.csv')\n",
    "int10y_daily = clean_data(int10y_daily,'',False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_usd_daily = pd.read_csv('./time_series_data/EUR_USD.csv')\n",
    "eur_usd_daily = clean_data(eur_usd_daily,'eur_usd',True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "usd_jpy_daily = pd.read_csv('./time_series_data/USD_JPY.csv')\n",
    "usd_jpy_daily = clean_data(usd_jpy_daily,'usd_jpy',True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all ecnomic indices together with bitcoin data\n",
    "# using left join to make sure all bitcoin data are included\n",
    "features_total = btc_daily.join([sp500_daily,n225_daily,sxxp_daily,vix_daily,dxsq_daily,metal_daily,int1mo_daily,\\\n",
    "                                int10y_daily,eur_usd_daily,usd_jpy_daily],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use forward fill so that holiday data are infered from previous business day's values\n",
    "# drop first fill NA because no previous data are available\n",
    "features_complete = features_total.fillna(method='ffill').dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using exchange rate to change everything back to USD\n",
    "\n",
    "features_complete['n225_close'] = features_complete['n225_close']/features_complete['usd_jpy_close']\n",
    "features_complete['sxxp_close'] = features_complete['sxxp_close']*features_complete['eur_usd_close']\n",
    "features_complete['dxsq_close'] = features_complete['dxsq_close']*features_complete['eur_usd_close']\n",
    "features_complete.drop(['eur_usd_close','usd_jpy_close'],axis=1,inplace=True)\n",
    "\n",
    "# taking log diff to compute log return\n",
    "for col in features_complete.columns:\n",
    "    features_complete[col] = np.log(features_complete[col]+1).diff()\n",
    "features_complete.dropna(axis=0,inplace=True)\n",
    "\n",
    "# create target 'y' to indicate whether the log return is positive or negative \n",
    "features_complete['y'] = features_complete['btc_close'].apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_news1 = pd.read_csv('./texts_data/bitcoin_news.csv')\n",
    "bitcoin_news1 = clean_texts(bitcoin_news1,['Summary','Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bitcoin_news2 = pd.read_csv('./texts_data/bitcoinist_news_cleaned.csv')\n",
    "bitcoin_news2 = clean_texts(bitcoin_news2,['Summary','Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\shif3\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "news_complete = pd.concat([bitcoin_news1[['Date','Title','Summary']],bitcoin_news2[['Date','Summary','Title']]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_complete['Text'] = news_complete['Title']+' '+news_complete['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_groupby = news_complete.groupby('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply concatenate all the news from one day to a single (potentially very long) string \n",
    "\n",
    "new_dict = {'Date':[],'Text':[]}\n",
    "for date, df in news_groupby:\n",
    "    s = ''\n",
    "    for t in df['Text']:\n",
    "        s = s+' '+t\n",
    "    s = s.strip()\n",
    "    new_dict['Date'].append(date)\n",
    "    new_dict['Text'].append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_complete2 = pd.DataFrame(new_dict).sort_values(by='Date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_complete2 = news_complete2.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>china bites into bitcoin bitcoins were worth n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-07</th>\n",
       "      <td>chilean nightclub to pioneer bitcoin in latin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-08</th>\n",
       "      <td>singapore government to tax some bitcoin trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-09</th>\n",
       "      <td>bitcoin conference new york city april 78 2014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-15</th>\n",
       "      <td>silicon valley vc thinks a single bitcoin will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text\n",
       "Date                                                         \n",
       "2014-01-06  china bites into bitcoin bitcoins were worth n...\n",
       "2014-01-07  chilean nightclub to pioneer bitcoin in latin ...\n",
       "2014-01-08  singapore government to tax some bitcoin trans...\n",
       "2014-01-09  bitcoin conference new york city april 78 2014...\n",
       "2014-01-15  silicon valley vc thinks a single bitcoin will..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_complete2.head()   # start from 2014-01-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join news data to features\n",
    "# fill NA with empty string\n",
    "features_complete = features_complete.join(news_complete2,how='left').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have several ideas to work with hourly bitcoin price/volume. But all of those ideas failed.\n",
    "# 1. work with artificially created 2d data and use CNN ... the network failed to converge on train set\n",
    "# 2. work with 1d data and use 1d convolution ... the network still failed to converge on train set\n",
    "# 3. just work with regular NN ... this time it easily overfit the train set\n",
    "\n",
    "#btc_hourly = pd.read_csv('./time_series_data/btc_hourly.txt')\n",
    "\n",
    "#btc_hourly = btc_hourly[['Date','Volume_Currency','Weighted_Price']]\n",
    "#btc_hourly.columns = ['Date','Volume','Price']\n",
    "\n",
    "#btc_hourly['Date'] = pd.to_datetime(btc_hourly['Date'],format=\"%Y-%m-%d\")\n",
    "\n",
    "#price_picture=[]\n",
    "#volume_picture = []\n",
    "#timelist = []\n",
    "#price_1d = []\n",
    "#volume_1d = []\n",
    "#feature_1d = []\n",
    "#btc_h_groupbydate = btc_hourly.groupby('Date')\n",
    "\n",
    "\n",
    "#for date,df in btc_h_groupbydate:\n",
    "#    timelist.append(date)\n",
    "#    vec_price = np.log(df['Price']).diff().iloc[1:]\n",
    "#    vec_vol = np.log(df['Volume']).diff().iloc[1:]\n",
    "#    vec_total = vec_price.append(vec_vol)\n",
    "#    feature_1d.append(vec_total)\n",
    "#    price_1d.append(vec_price)\n",
    "#    volume_1d.append(vec_vol)\n",
    "#    price_picture.append(create2d(vec_price,23,12,12))\n",
    "#    volume_picture.append(create2d(vec_vol,23,12,12))\n",
    "\n",
    "#timelist = timelist[:-1]\n",
    "#price_picture = price_picture[:-1]\n",
    "#volume_picture = volume_picture[:-1]\n",
    "#price_1d = price_1d[:-1]\n",
    "#volume_1d = volume_1d[:-1]\n",
    "#feature_1d = feature_1d[:-1]\n",
    "\n",
    "#price_picture = np.concatenate([np.zeros((1774,12,12),dtype=np.float32),np.array(price_picture,dtype=np.float32)],axis = 0)\n",
    "#volume_picture = np.concatenate([np.zeros((1774,12,12),dtype=np.float32),np.array(volume_picture,dtype=np.float32)],axis = 0)\n",
    "#price_1d = np.concatenate([np.zeros((1774,23),dtype=np.float32),np.array(price_1d,dtype=np.float32)],axis = 0)\n",
    "#volume_1d = np.concatenate([np.zeros((1774,23),dtype=np.float32),np.array(volume_1d,dtype=np.float32)],axis = 0)\n",
    "#feature_1d = np.concatenate([np.zeros((1774,46),dtype=np.float32),np.array(feature_1d,dtype=np.float32)],axis = 0)\n",
    "\n",
    "#total_picture = np.stack([price_picture,volume_picture],axis=1)  # need NCWH for better training performance\n",
    "#total_1d = np.stack([price_1d,volume_1d],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 15)\n",
      "(1000, 1)\n",
      "(100, 15)\n",
      "(100, 1)\n",
      "(1000,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# create different train/test sets for different models\n",
    "\n",
    "# these names roughly correspond to the various inputs of functions from the scripts\n",
    "# hourly_feature.py, lstm_train.py, text_feature.py\n",
    "\n",
    "train = np.array(features_complete.iloc[1869:2869,0:15],dtype=np.float32)\n",
    "print(train.shape)\n",
    "\n",
    "train_label = np.array(features_complete['y'],dtype=np.float32)[1870:2870].reshape(-1,1)\n",
    "print(train_label.shape)\n",
    "\n",
    "test = np.array(features_complete.iloc[2869:-1,0:15],dtype=np.float32)\n",
    "print(test.shape)\n",
    "\n",
    "test_label = np.array(features_complete['y'],dtype=np.float32)[2870:].reshape(-1,1)\n",
    "print(test_label.shape)\n",
    "\n",
    "train_text = np.array(features_complete['Text'][1869:2869])\n",
    "print(train_text.shape)\n",
    "\n",
    "test_text = np.array(features_complete['Text'][2869:-1])\n",
    "print(test_text.shape)\n",
    "\n",
    "#train_image = total_picture[1869:2869]\n",
    "#train_image.shape\n",
    "\n",
    "#train_1d = total_1d[1869:2869]\n",
    "#train_1d.shape\n",
    "\n",
    "#test_image = total_picture[2869:-1]\n",
    "#test_image.shape\n",
    "\n",
    "#test_1d = total_1d[2869:-1]\n",
    "#test_1d.shape\n",
    "\n",
    "#train_price_1d = price_1d[1869:2869]\n",
    "#train_price_1d.shape\n",
    "\n",
    "#test_price_1d = price_1d[2869:-1]\n",
    "#test_price_1d.shape\n",
    "\n",
    "#train_volume_1d = volume_1d[1869:2869]\n",
    "#train_volume_1d.shape\n",
    "\n",
    "#test_volume_1d = volume_1d[2869:-1]\n",
    "#test_volume_1d.shape\n",
    "\n",
    "#train_feature_1d = feature_1d[1869:2869]\n",
    "#train_feature_1d.shape\n",
    "\n",
    "#test_feature_1d = feature_1d[2869:-1]\n",
    "#test_feature_1d.shape\n",
    "\n",
    "#total_text = np.array(features_complete['Text'][1869:-1])\n",
    "#total_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we trained a model using word embedding\n",
    "# and we extract the last layer before the final dense layer and add this to the features\n",
    "\n",
    "# first, run the following codes to create a model and save its parameters\n",
    "\n",
    "#from text_feature import *\n",
    "#train_text_feature(100,train_text,train_label,test_text,test_label)\n",
    "\n",
    "# then, run the following codes to extract the last hidden layer in the model\n",
    "\n",
    "#total_text_feature = get_text_feature(total_text)\n",
    "#total_text_feature = total_text_feature.astype(np.float32)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# then, save the numpy array as pickle file\n",
    "\n",
    "#with open('text_feature.pkl', 'wb') as f:  \n",
    "#    pickle.dump(total_text_feature, f)\n",
    "\n",
    "# after it is saved as pickle file, we don't need to rerun the above code each time\n",
    "# we can directly read a numpy array from the pickle file\n",
    "with open('text_feature.pkl','rb') as f:  \n",
    "    total_text_feature = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_text_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 31)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_train_features = np.concatenate([train,total_text_feature[:1000]],axis=1)\n",
    "lstm_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 31)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_test_features = np.concatenate([test,total_text_feature[1000:]],axis=1)\n",
    "lstm_test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 31)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.concatenate([lstm_train_features,lstm_test_features],axis=0)\n",
    "x = x[1:]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.concatenate([train_label,test_label],axis=0)\n",
    "y = y[1:]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# enable eager execution\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eager_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for epoch 0: 1.3448596000671387 sec\n",
      "\n",
      "Time taken for epoch 1: 0.3195221424102783 sec\n",
      "\n",
      "Time taken for epoch 2: 0.3121342658996582 sec\n",
      "\n",
      "Time taken for epoch 3: 0.31519079208374023 sec\n",
      "\n",
      "Time taken for epoch 4: 0.3335709571838379 sec\n",
      "\n",
      "Time taken for epoch 5: 0.32268548011779785 sec\n",
      "\n",
      "Time taken for epoch 6: 0.30518245697021484 sec\n",
      "\n",
      "Time taken for epoch 7: 0.3002312183380127 sec\n",
      "\n",
      "Time taken for epoch 8: 0.3291194438934326 sec\n",
      "\n",
      "Time taken for epoch 9: 0.29244303703308105 sec\n",
      "\n",
      "Time taken for epoch 10: 0.32365870475769043 sec\n",
      "\n",
      "Time taken for epoch 11: 0.3024559020996094 sec\n",
      "\n",
      "Time taken for epoch 12: 0.29841089248657227 sec\n",
      "\n",
      "Time taken for epoch 13: 0.28620362281799316 sec\n",
      "\n",
      "Time taken for epoch 14: 0.31017112731933594 sec\n",
      "\n",
      "Time taken for epoch 15: 0.309173583984375 sec\n",
      "\n",
      "Time taken for epoch 16: 0.3000519275665283 sec\n",
      "\n",
      "Time taken for epoch 17: 0.31612539291381836 sec\n",
      "\n",
      "Time taken for epoch 18: 0.3049156665802002 sec\n",
      "\n",
      "Time taken for epoch 19: 0.3666234016418457 sec\n",
      "\n",
      "Time taken for epoch 20: 0.3167734146118164 sec\n",
      "\n",
      "Time taken for epoch 21: 0.29923462867736816 sec\n",
      "\n",
      "Time taken for epoch 22: 0.3101792335510254 sec\n",
      "\n",
      "Time taken for epoch 23: 0.30278801918029785 sec\n",
      "\n",
      "Time taken for epoch 24: 0.31021928787231445 sec\n",
      "\n",
      "Time taken for epoch 25: 0.3378739356994629 sec\n",
      "\n",
      "Time taken for epoch 26: 0.3040885925292969 sec\n",
      "\n",
      "Time taken for epoch 27: 0.33809542655944824 sec\n",
      "\n",
      "Time taken for epoch 28: 0.31319308280944824 sec\n",
      "\n",
      "Time taken for epoch 29: 0.29647111892700195 sec\n",
      "\n",
      "Time taken for epoch 30: 0.2968320846557617 sec\n",
      "\n",
      "Time taken for epoch 31: 0.3039565086364746 sec\n",
      "\n",
      "Time taken for epoch 32: 0.3088696002960205 sec\n",
      "\n",
      "Time taken for epoch 33: 0.34206199645996094 sec\n",
      "\n",
      "Time taken for epoch 34: 0.3231775760650635 sec\n",
      "\n",
      "Time taken for epoch 35: 0.33214855194091797 sec\n",
      "\n",
      "Time taken for epoch 36: 0.3073699474334717 sec\n",
      "\n",
      "Time taken for epoch 37: 0.30832648277282715 sec\n",
      "\n",
      "Time taken for epoch 38: 0.3181464672088623 sec\n",
      "\n",
      "Time taken for epoch 39: 0.3111591339111328 sec\n",
      "\n",
      "Time taken for epoch 40: 0.3117685317993164 sec\n",
      "\n",
      "Time taken for epoch 41: 0.3079686164855957 sec\n",
      "\n",
      "Time taken for epoch 42: 0.3081681728363037 sec\n",
      "\n",
      "Time taken for epoch 43: 0.30019187927246094 sec\n",
      "\n",
      "Time taken for epoch 44: 0.3202705383300781 sec\n",
      "\n",
      "Time taken for epoch 45: 0.32364320755004883 sec\n",
      "\n",
      "Time taken for epoch 46: 0.2983558177947998 sec\n",
      "\n",
      "Time taken for epoch 47: 0.2952103614807129 sec\n",
      "\n",
      "Time taken for epoch 48: 0.29437947273254395 sec\n",
      "\n",
      "Time taken for epoch 49: 0.29428529739379883 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the test accuracy is low...roughly 50%... no better than random guess\n",
    "# the train accuracy, however, is approaching 94% with merely 50 iterations\n",
    "accuracy_train,accuracy_test = train_arc4(50,x,y,\n",
    "               rnn_drop_prob = 0.5,batch_size=100,time_window = 100,num_units1=5,num_units2=5, lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4099,\n",
       " 0.4224,\n",
       " 0.5339,\n",
       " 0.5757,\n",
       " 0.5793,\n",
       " 0.5731,\n",
       " 0.5846,\n",
       " 0.5827,\n",
       " 0.5824,\n",
       " 0.587,\n",
       " 0.5721,\n",
       " 0.5798,\n",
       " 0.5733,\n",
       " 0.5729,\n",
       " 0.5861,\n",
       " 0.5845,\n",
       " 0.5771,\n",
       " 0.5807,\n",
       " 0.5862,\n",
       " 0.5755,\n",
       " 0.5775,\n",
       " 0.5725,\n",
       " 0.5793,\n",
       " 0.5811,\n",
       " 0.5867,\n",
       " 0.5872,\n",
       " 0.6113,\n",
       " 0.6172,\n",
       " 0.6121,\n",
       " 0.6201,\n",
       " 0.6266,\n",
       " 0.6463,\n",
       " 0.6615,\n",
       " 0.6584,\n",
       " 0.6875,\n",
       " 0.6819,\n",
       " 0.7015,\n",
       " 0.6971,\n",
       " 0.7107,\n",
       " 0.7125,\n",
       " 0.741,\n",
       " 0.7576,\n",
       " 0.7616,\n",
       " 0.7713,\n",
       " 0.7784,\n",
       " 0.793,\n",
       " 0.7887,\n",
       " 0.7995,\n",
       " 0.7888,\n",
       " 0.7955,\n",
       " 0.7983,\n",
       " 0.8102,\n",
       " 0.8029,\n",
       " 0.815,\n",
       " 0.8001,\n",
       " 0.7891,\n",
       " 0.7882,\n",
       " 0.804,\n",
       " 0.7988,\n",
       " 0.8101,\n",
       " 0.8163,\n",
       " 0.8169,\n",
       " 0.8249,\n",
       " 0.8101,\n",
       " 0.8359,\n",
       " 0.8144,\n",
       " 0.8343,\n",
       " 0.8022,\n",
       " 0.8293,\n",
       " 0.842,\n",
       " 0.8243,\n",
       " 0.8245,\n",
       " 0.8422,\n",
       " 0.8457,\n",
       " 0.8468,\n",
       " 0.8278,\n",
       " 0.84,\n",
       " 0.8321,\n",
       " 0.8462,\n",
       " 0.8514,\n",
       " 0.8564,\n",
       " 0.8476,\n",
       " 0.8699,\n",
       " 0.845,\n",
       " 0.8417,\n",
       " 0.8725,\n",
       " 0.86,\n",
       " 0.8682,\n",
       " 0.8711,\n",
       " 0.8634,\n",
       " 0.8774,\n",
       " 0.8642,\n",
       " 0.8658,\n",
       " 0.856,\n",
       " 0.8659,\n",
       " 0.8727,\n",
       " 0.8706,\n",
       " 0.8949,\n",
       " 0.8656,\n",
       " 0.8902,\n",
       " 0.8581,\n",
       " 0.8613,\n",
       " 0.8733,\n",
       " 0.8907,\n",
       " 0.8813,\n",
       " 0.8718,\n",
       " 0.8777,\n",
       " 0.8963,\n",
       " 0.8891,\n",
       " 0.8745,\n",
       " 0.9003,\n",
       " 0.8702,\n",
       " 0.8795,\n",
       " 0.873,\n",
       " 0.8787,\n",
       " 0.8843,\n",
       " 0.8671,\n",
       " 0.8944,\n",
       " 0.8749,\n",
       " 0.8786,\n",
       " 0.8762,\n",
       " 0.8875,\n",
       " 0.8932,\n",
       " 0.8947,\n",
       " 0.8711,\n",
       " 0.8727,\n",
       " 0.8751,\n",
       " 0.884,\n",
       " 0.8849,\n",
       " 0.8756,\n",
       " 0.8766,\n",
       " 0.8821,\n",
       " 0.882,\n",
       " 0.8996,\n",
       " 0.8861,\n",
       " 0.8588,\n",
       " 0.8949,\n",
       " 0.9019,\n",
       " 0.8823,\n",
       " 0.8767,\n",
       " 0.8804,\n",
       " 0.8899,\n",
       " 0.8833,\n",
       " 0.8884,\n",
       " 0.8812,\n",
       " 0.8752,\n",
       " 0.8919,\n",
       " 0.8841,\n",
       " 0.8674,\n",
       " 0.8872,\n",
       " 0.8919,\n",
       " 0.8893,\n",
       " 0.8875,\n",
       " 0.8896,\n",
       " 0.8736,\n",
       " 0.8842,\n",
       " 0.8867,\n",
       " 0.8851,\n",
       " 0.8797,\n",
       " 0.8968,\n",
       " 0.8908,\n",
       " 0.8689,\n",
       " 0.8822,\n",
       " 0.8886,\n",
       " 0.8905,\n",
       " 0.8766,\n",
       " 0.8832,\n",
       " 0.9001,\n",
       " 0.8771,\n",
       " 0.8959,\n",
       " 0.8852,\n",
       " 0.8882,\n",
       " 0.886,\n",
       " 0.904,\n",
       " 0.8902,\n",
       " 0.881,\n",
       " 0.8914,\n",
       " 0.8819,\n",
       " 0.8736,\n",
       " 0.9074,\n",
       " 0.8764,\n",
       " 0.8857,\n",
       " 0.8943,\n",
       " 0.8773,\n",
       " 0.8959,\n",
       " 0.8827,\n",
       " 0.8924,\n",
       " 0.9014,\n",
       " 0.8957,\n",
       " 0.8771,\n",
       " 0.892,\n",
       " 0.8896,\n",
       " 0.8846,\n",
       " 0.8914,\n",
       " 0.8954,\n",
       " 0.8997,\n",
       " 0.892,\n",
       " 0.8942,\n",
       " 0.8974,\n",
       " 0.89,\n",
       " 0.8987,\n",
       " 0.888,\n",
       " 0.8921,\n",
       " 0.8951,\n",
       " 0.8903,\n",
       " 0.8975,\n",
       " 0.8789,\n",
       " 0.8902,\n",
       " 0.8756,\n",
       " 0.8982,\n",
       " 0.8823,\n",
       " 0.8988,\n",
       " 0.8881,\n",
       " 0.9041,\n",
       " 0.901,\n",
       " 0.9028,\n",
       " 0.8902,\n",
       " 0.902,\n",
       " 0.8918,\n",
       " 0.8886,\n",
       " 0.8835,\n",
       " 0.8992,\n",
       " 0.9082,\n",
       " 0.8989,\n",
       " 0.8944,\n",
       " 0.9045,\n",
       " 0.901,\n",
       " 0.8863,\n",
       " 0.8898,\n",
       " 0.9044,\n",
       " 0.9048,\n",
       " 0.8812,\n",
       " 0.8851,\n",
       " 0.909,\n",
       " 0.8914,\n",
       " 0.8907,\n",
       " 0.9004,\n",
       " 0.8872,\n",
       " 0.8962,\n",
       " 0.9034,\n",
       " 0.9025,\n",
       " 0.8979,\n",
       " 0.9132,\n",
       " 0.8974,\n",
       " 0.9021,\n",
       " 0.8878,\n",
       " 0.8964,\n",
       " 0.9015,\n",
       " 0.8978,\n",
       " 0.902,\n",
       " 0.9019,\n",
       " 0.9162,\n",
       " 0.8951,\n",
       " 0.8943,\n",
       " 0.9005,\n",
       " 0.9056,\n",
       " 0.9028,\n",
       " 0.9094,\n",
       " 0.891,\n",
       " 0.8942,\n",
       " 0.9074,\n",
       " 0.9037,\n",
       " 0.9062,\n",
       " 0.8987,\n",
       " 0.907,\n",
       " 0.9139,\n",
       " 0.8988,\n",
       " 0.8964,\n",
       " 0.8966,\n",
       " 0.9066,\n",
       " 0.9053,\n",
       " 0.9039,\n",
       " 0.8956,\n",
       " 0.8955,\n",
       " 0.8978,\n",
       " 0.907,\n",
       " 0.9123,\n",
       " 0.9133,\n",
       " 0.9113,\n",
       " 0.8961,\n",
       " 0.9014,\n",
       " 0.902,\n",
       " 0.8996,\n",
       " 0.9053,\n",
       " 0.9177,\n",
       " 0.9005,\n",
       " 0.9174,\n",
       " 0.9106,\n",
       " 0.903,\n",
       " 0.9117,\n",
       " 0.8986,\n",
       " 0.8887,\n",
       " 0.9145,\n",
       " 0.9044,\n",
       " 0.919,\n",
       " 0.9172,\n",
       " 0.8961,\n",
       " 0.9132,\n",
       " 0.9066,\n",
       " 0.8965,\n",
       " 0.9095,\n",
       " 0.9079,\n",
       " 0.9209,\n",
       " 0.9071,\n",
       " 0.8973,\n",
       " 0.9014,\n",
       " 0.9005,\n",
       " 0.9126,\n",
       " 0.9081,\n",
       " 0.9062,\n",
       " 0.8952,\n",
       " 0.9086,\n",
       " 0.9183,\n",
       " 0.9116,\n",
       " 0.9229,\n",
       " 0.9159,\n",
       " 0.9216,\n",
       " 0.9174,\n",
       " 0.9026,\n",
       " 0.8975,\n",
       " 0.9123,\n",
       " 0.9017,\n",
       " 0.9084,\n",
       " 0.911,\n",
       " 0.91,\n",
       " 0.9061,\n",
       " 0.9053,\n",
       " 0.9139,\n",
       " 0.9115,\n",
       " 0.9166,\n",
       " 0.9134,\n",
       " 0.9172,\n",
       " 0.9049,\n",
       " 0.9176,\n",
       " 0.9113,\n",
       " 0.9069,\n",
       " 0.9191,\n",
       " 0.9148,\n",
       " 0.9162,\n",
       " 0.9245,\n",
       " 0.9083,\n",
       " 0.9116,\n",
       " 0.9171,\n",
       " 0.9239,\n",
       " 0.9225,\n",
       " 0.9141,\n",
       " 0.914,\n",
       " 0.9094,\n",
       " 0.8959,\n",
       " 0.9198,\n",
       " 0.9149,\n",
       " 0.9124,\n",
       " 0.9197,\n",
       " 0.9182,\n",
       " 0.9248,\n",
       " 0.907,\n",
       " 0.9172,\n",
       " 0.9128,\n",
       " 0.9172,\n",
       " 0.9159,\n",
       " 0.9189,\n",
       " 0.9127,\n",
       " 0.9152,\n",
       " 0.9127,\n",
       " 0.9194,\n",
       " 0.9254,\n",
       " 0.9224,\n",
       " 0.9164,\n",
       " 0.9117,\n",
       " 0.9232,\n",
       " 0.9207,\n",
       " 0.924,\n",
       " 0.9138,\n",
       " 0.9126,\n",
       " 0.9226,\n",
       " 0.9179,\n",
       " 0.9174,\n",
       " 0.9255,\n",
       " 0.9157,\n",
       " 0.9247,\n",
       " 0.919,\n",
       " 0.9254,\n",
       " 0.914,\n",
       " 0.9362,\n",
       " 0.9364,\n",
       " 0.9186,\n",
       " 0.9227,\n",
       " 0.9285,\n",
       " 0.923,\n",
       " 0.9273,\n",
       " 0.9168,\n",
       " 0.9271,\n",
       " 0.928,\n",
       " 0.9189,\n",
       " 0.9185,\n",
       " 0.9409,\n",
       " 0.9219,\n",
       " 0.923,\n",
       " 0.926,\n",
       " 0.9236,\n",
       " 0.9215,\n",
       " 0.922,\n",
       " 0.9375,\n",
       " 0.9278,\n",
       " 0.9347,\n",
       " 0.9194,\n",
       " 0.93,\n",
       " 0.9225,\n",
       " 0.9276,\n",
       " 0.9321,\n",
       " 0.9274,\n",
       " 0.9245,\n",
       " 0.9282,\n",
       " 0.9222,\n",
       " 0.9313,\n",
       " 0.93,\n",
       " 0.9296,\n",
       " 0.9281,\n",
       " 0.9301,\n",
       " 0.9233,\n",
       " 0.9303,\n",
       " 0.9289,\n",
       " 0.9304,\n",
       " 0.929,\n",
       " 0.9234,\n",
       " 0.9301,\n",
       " 0.9328,\n",
       " 0.9317,\n",
       " 0.9358,\n",
       " 0.9285,\n",
       " 0.9351,\n",
       " 0.9436,\n",
       " 0.9364,\n",
       " 0.9412,\n",
       " 0.929,\n",
       " 0.9376,\n",
       " 0.9373,\n",
       " 0.9321,\n",
       " 0.9312,\n",
       " 0.9295,\n",
       " 0.9307,\n",
       " 0.9431,\n",
       " 0.9242,\n",
       " 0.938,\n",
       " 0.9341,\n",
       " 0.9325,\n",
       " 0.9277,\n",
       " 0.937,\n",
       " 0.9295,\n",
       " 0.9378]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.51,\n",
       " 0.51,\n",
       " 0.51,\n",
       " 0.51,\n",
       " 0.51,\n",
       " 0.46,\n",
       " 0.43,\n",
       " 0.46,\n",
       " 0.46,\n",
       " 0.44,\n",
       " 0.46,\n",
       " 0.47,\n",
       " 0.46,\n",
       " 0.49,\n",
       " 0.48,\n",
       " 0.48,\n",
       " 0.49,\n",
       " 0.47,\n",
       " 0.48,\n",
       " 0.48,\n",
       " 0.5,\n",
       " 0.49,\n",
       " 0.48,\n",
       " 0.52,\n",
       " 0.5,\n",
       " 0.48,\n",
       " 0.5,\n",
       " 0.53,\n",
       " 0.45,\n",
       " 0.53,\n",
       " 0.55,\n",
       " 0.55,\n",
       " 0.48,\n",
       " 0.52,\n",
       " 0.52,\n",
       " 0.52,\n",
       " 0.51,\n",
       " 0.51,\n",
       " 0.5,\n",
       " 0.46,\n",
       " 0.46,\n",
       " 0.44,\n",
       " 0.44,\n",
       " 0.45,\n",
       " 0.42,\n",
       " 0.45,\n",
       " 0.47,\n",
       " 0.42,\n",
       " 0.45,\n",
       " 0.45]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
